{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Linear Regression***\n",
    "\n",
    "Linear regression is basically a **statistical method** that helps us understand the relationship between one **dependent variable** (the thing we’re trying to predict) and one or more **independent variables** (the factors that might influence it). It’s super useful for **making predictions** and **analyzing trends** in data.  \n",
    "\n",
    "It’s actually a **supervised machine learning algorithm**, meaning it learns from **labeled data** the data where we already know the inputs and their correct outputs. The goal is to find the **best-fit line** that represents the relationship between these variables. Once we have this line, we can use it to **predict future values** based on new inputs.  \n",
    "\n",
    "Now, the big question is: **how does it find the best line?** The model looks at all the data points and tries to draw a line that minimizes the difference between the **actual values** and the **predicted values**. It does this by using a technique called **Least Squares**, which helps find the line with the smallest possible errors. Basically, it’s all about reducing the gap between what the model predicts and what actually happens.  \n",
    "\n",
    "Linear regression is mainly used for predicting **continuous values**, like things like prices, sales, temperatures, or even a person’s salary based on experience.  \n",
    "\n",
    "For example, let’s say we want to predict the price of a book. Some things that might affect the price include:  \n",
    "- Is the author famous?  \n",
    "- How many pages does it have?  \n",
    "- Is it old or newly released?  \n",
    "- Is it in high demand?  \n",
    "\n",
    "The model takes all these factors, looks for patterns in past data, and creates a formula to predict the price of similar books in the future. The more relevant data we have, the better the predictions.  \n",
    "\n",
    "One important thing to keep in mind is that **linear regression assumes a straight line relationship** between the variables. If the data doesn’t follow a linear pattern, this model might not give the best results. In that case, we might need to use something more advanced, like polynomial regression or decision trees.  \n",
    "\n",
    "So, while linear regression is simple, it’s super powerful and widely used in **finance, marketing, sales forecasting, and even sports analytics**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***What is the Best Fit Line?*** \n",
    "\n",
    "Our main goal with linear regression is to find the **best-fit line**, meaning the line that keeps the error between the **predicted** and **actual** values as small as possible. The smaller the error, the better the fit.  \n",
    "\n",
    "The **best-fit line** is a straight line that shows the relationship between the **dependent** and **independent** variables. The **slope** of the line tells us how much the dependent variable changes for each unit increase in the independent variable(s).  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Linear regression PIC.png\" alt=\"Linear Regression\">\n",
    "  <br>\n",
    "  <i>Linear Regression</i>\n",
    "</p>  \n",
    "\n",
    "### **Main Takeaways:**  \n",
    " \n",
    "\n",
    "- **Y (dependent variable)** → This is what we’re trying to predict (output).  \n",
    "- **X (independent variable)** → This is what we use to make predictions (input).  \n",
    "- **Y (Observed Value)** → The actual value (red dots).  \n",
    "- **Yp (Predicted Value)** → The value our regression model predicts (on the blue line).  \n",
    "- **Random Error (εi)** → The difference between the actual and predicted values (we want this to be as small as possible).  \n",
    "- **Intercept (θ1)** → The point where the line crosses the Y-axis (when X = 0).  \n",
    "- **Slope (θi)** → Shows how much Y changes when X increases by 1 unit.  \n",
    "\n",
    "**So, how does this actually work in real life?**\n",
    "\n",
    "Linear regression helps us predict **Y** (dependent variable) based on **X** (independent variable).  \n",
    "- In this example, **X** could be **work experience**, and **Y** could be **salary**.  \n",
    "- The blue line is the **best-fit line**, meaning it best represents the trend in the data.  \n",
    "\n",
    "***The closer the red dots are to the blue line, the better our model is.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alright, so that’s the gist of linear regression! The whole idea is to find the best-fit line that makes our predictions as close as possible to the real values. The better the fit, the more useful our model is.**\n",
    "\n",
    "Next, we’re gonna dig deeper into:  \n",
    "- **Hypothesis function in Linear Regression** – how we actually define this line.  \n",
    "- **How to update θ1 and θ2 values** to get the most accurate predictions.  \n",
    "- **Types of Linear Regression** – because not every problem fits a simple straight line.  \n",
    "\n",
    "***Keep learning and enjoy the journey.***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
