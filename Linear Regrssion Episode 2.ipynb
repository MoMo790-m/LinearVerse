{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Hypothesis Function***\n",
    "\n",
    "Alright, let's dive into the fun part of linear regression. First, we need to understand the basic assumptions.  \n",
    "\n",
    "There are two main assumptions:  \n",
    "\n",
    "1. **Linearity**  \n",
    "   This means there's a relationship between the independent variable $X$ and the dependent variable **$Y$**. For example, the more experience you have, the higher your salary. Think of it like this: If a chef spends more years in the kitchen, their food (hopefully) gets better, and they get paid more.  \n",
    "\n",
    "2. **Independence**  \n",
    "   This means that the observations in the dataset don’t influence each other. If one data point has an error, it doesn’t affect the others. Imagine if one student's bad exam grade caused another student's grade to drop too – that would be weird, right? Luckily, that’s not how independent data works.  \n",
    "\n",
    "\n",
    "**Now, let’s get to the math.**  \n",
    "\n",
    "If we assume a linear relationship between experience ($X$) and salary ($Y$), we can predict salaries using this formula:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{Y} = \\theta_1 + \\theta_2 X\n",
    "$$\n",
    "\n",
    "**Or, for individual data points:**\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\theta_1 + \\theta_2 x_i\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "\n",
    "- $ \\hat{Y} $ is the predicted salary  \n",
    "- $ \\theta_1 $ is the intercept (the starting salary when experience is zero)  \n",
    "- $ \\theta_2 $ is the coefficient of $X$ (how much salary increases per year of experience)  \n",
    "- $ x_i $ is the given experience   \n",
    "\n",
    "**Our goal is to find the best values for $ \\theta_1 $ and $ \\theta_2 $ so that the line fits the data as well as possible. Once we get those values, we can use our model to predict salaries for any given experience level.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Now, how do we update our parameters to get the best fit line for predictions?** \n",
    "\n",
    "Let’s emphasize an important point that we will discuss frequently:  \n",
    "Our goal is to find the best values for $ \\theta_1 $ and $ \\theta_2 $ to **minimize** the error between the `predicted value` and the `actual value`.  \n",
    "\n",
    "Based on this logic, we will update our parameters iteratively to achieve this goal.  \n",
    "\n",
    "The best way to reduce the error between the predicted and actual values is by minimizing the following function:\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "**Don't worry about the notation right now we will break it down step by step, and soon you will understand it perfectly.**\n",
    "\n",
    "**For now, just take a moment to appreciate the beauty and power of mathematics!.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aren’t you curious about the different types of regression and how they work? Well, let me introduce you to a few of them!**\n",
    "\n",
    "If there’s only **one** independent variable, this represents the simplest type of linear regression, known as **Simple Linear Regression** (or **Univariate Linear Regression**). It’s like predicting salary based only on years of experience just one factor affecting the outcome.  \n",
    "\n",
    "But if we have **multiple** features, then this leads to the second type: **Multiple Linear Regression** (or **Multivariate Regression**). Here, we’re considering **several** factors at once—like predicting salary based on experience, education level, and number of certifications.  \n",
    "\n",
    "**So, in simple terms:**\n",
    "- If we’re using **one** factor to predict something → **Simple Linear Regression**  \n",
    "- If we’re using **multiple** factors → **Multiple Linear Regression**  \n",
    "\n",
    "Both types follow the same core idea: **finding the best-fit line to make accurate predictions!** The only difference is how many factors we take into account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That’s a wrap for this session! But I’ll leave you with a bit of mystery there’s still more to uncover. In the next session, we’ll dive deeper into both types of regression and break them down step by step.**\n",
    "\n",
    "**So, stay curious and get ready for what’s next!** \n",
    "\n",
    "***And remember learning is a journey, not a race. Enjoy every step, celebrate your progress, and most importantly, have fun with it!***\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
